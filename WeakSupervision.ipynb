{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5c3dbc-7e8d-47eb-8c78-591c4edc2347",
   "metadata": {},
   "source": [
    "Obtaining a sufficient amount of high-quality training data is one of the crucial points and most formidable challenges in deep learning-based natural language processing. In this work, we present GGTWEAK (German Gene Tagging with Weak Supervision). In conventional settings all data must be labelled manually while complexity often does not allow for the involvement of non-experts for this laborious and thus costly task. This is especially true for molecular data, which is hard to discriminate from common abbreviations syntactically. Therefore, GGTWEAK provides a baseline bridging the gap between English gene taggers and models usable for German. GGTWEAK saves human resources compared to its English counterparts and potentially can be trained for free after development on available data. \n",
    "We design labelling functions based on the structure of gene naming conventions and databases from both the medical and general domain. Following that, we train a hidden Markov model for label aggregration. Based on our weakly labelled data, we finally train a German BERT model for named entity recognition. This weak supervision approach for gene labelling in the German language leverages the skweak framework achieving an entity-level F1 score of 60.4% on our test set, while dealing with a highly unbalanced data from the German Guideline Program in Oncology NLP Corpus. The NER model trained on the same development dataset with quantitatively less strong labels achieved 53.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5a326a-91b3-4057-af63-82389654e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "from spacy.tokens import Span, DocBin\n",
    "from spacy_transformers import Transformer\n",
    "from spacy_transformers.pipeline_component import DEFAULT_CONFIG\n",
    "from skweak import heuristics, gazetteers, generative, utils, base\n",
    "from skweak.base import SpanAnnotator\n",
    "from skweak.heuristics import SpanEditorAnnotator, VicinityAnnotator, SpanConstraintAnnotator\n",
    "from skweak.analysis import LFAnalysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipynb\n",
    "import string\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "from ipynb.fs.full.evaluation import evaluate, get_results, compute_raw_numbers, _get_probs, show_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeaf50d-2649-437d-83e5-6af3f8927bd0",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712ce01-00dd-4afd-af2d-eca3788c264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
    "nlp.add_pipe('sentencizer')\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "infixes = nlp.Defaults.infixes + [r'([-])']\n",
    "doc_bin = DocBin()\n",
    "spacy.require_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df70ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "sentences = list(Path('../ggponc_data/sentences/all_files_sentences').glob('*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(file):\n",
    "    df = pd.read_csv(file, delimiter='\\t', names =['text'] )\n",
    "    df['file'] = file.stem\n",
    "    df['sentence_id'] = df.index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [get_df(file) for file in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = pd.concat(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54153a7-1586-4cd3-9f05-b95aca1bea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate data stats (number of genes, sentences, etc...) -> Table for Materials\n",
    "\n",
    "intersection_db = list(set(cosmic_census_lower) & set(CIVIC_genes_lower) & set(omim_list_lower))\n",
    "union_db = set(set(cosmic_census_lower).union(set(CIVIC_genes_lower)).union(set(omim_list_lower)))\n",
    "print(len(intersection_db))\n",
    "print(len(union_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7c442-07f8-4727-a33a-cb84dca20aa4",
   "metadata": {},
   "source": [
    "# Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a9d007-e413-4718-8e00-dbe9d1f6ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gazetteers\n",
    "\n",
    "df = pd.read_csv('nightly-GeneSummaries.tsv', sep='\\t')\n",
    "CIVIC_genes = df['name'].tolist()\n",
    "CIVIC_genes_lower = [c.lower() for c in CIVIC_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nightly-VariantSummaries.tsv', sep='\\t', error_bad_lines=False )\n",
    "CIVIC_variants = df['variant'].tolist()\n",
    "CIVIC_variants_lower = [c.lower() for c in CIVIC_variants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2354cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "omim_list = pd.read_csv(\"mim2gene.csv\")\n",
    "omim_list = omim_list['name'].tolist()\n",
    "omim_list_lower = [o.lower() for o in omim_list]\n",
    "short_genes = []\n",
    "for u in omim_list:\n",
    "    if len(u)<3:\n",
    "        short_genes.append(u)\n",
    "less_short_genes = []\n",
    "for u in omim_list:\n",
    "    if len(u)<5 and len(u)>2:\n",
    "        less_short_genes.append(u)\n",
    "print(len(omim_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faecaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_census = pd.read_csv(\"cancer_gene_census.csv\")\n",
    "cosmic_census = cosmic_census['Gene Symbol'].tolist()\n",
    "cosmic_census_lower = [c.lower() for c in cosmic_census]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22474545",
   "metadata": {},
   "source": [
    "\"omim\" is based on the Online Mendelian Inheritance in Man (OMIM) database and checks whether tokens are present in its list of 16,767 approved gene symbols in lowercase as the diversity of genes often shows in volatile capitalization. To increase precision, genes with a length shorter than three characters are matched only correctly cased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6813e7a-8d36-4da2-9749-9c9b6ffc6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def omim(doc):\n",
    "    for tok in doc:\n",
    "        if tok.text.lower() in omim_list_lower and tok.text.lower() not in stops and len(tok.text.lower())>=3:\n",
    "            yield tok.i, tok.i+1, \"Gen\"\n",
    "omim = heuristics.FunctionAnnotator(\"omim\", omim) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3983b3",
   "metadata": {},
   "source": [
    "\"cue_cosmic_census\" is based on the Catalogue of Somatic Mutations in Cancer (COSMIC) database \n",
    "If a token contains a gene symbol which is listed here, this token and its successor are annotated as a gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosmic(doc):\n",
    "    for tok in doc:\n",
    "        for cue in cosmic_census:\n",
    "            if tok.text.find(cue) == -1:\n",
    "                continue\n",
    "            else:\n",
    "                yield tok.i, tok.i+1, \"Gen\"\n",
    "cue_cosmic_census = heuristics.FunctionAnnotator(\"cue_cosmic_census\", cosmic)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305adb9",
   "metadata": {},
   "source": [
    "\"cue_civic\" is based on the Clinical Interpretation of Variants in Cancer (CIViC) database. If a token contains a gene which is listed in the database, this and the next token are labelled a gene. This way, we do not restrict the function to a 100 percent match but leave it some leeway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912fc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def civic(doc):\n",
    "    for tok in doc:\n",
    "        for cue in CIVIC_genes:\n",
    "            if tok.text.find(cue) == -1:\n",
    "                continue\n",
    "            else:\n",
    "                yield tok.i, tok.i+1, \"Gen\"\n",
    "cue_civic = heuristics.FunctionAnnotator(\"cue_civic\", civic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e52e0a",
   "metadata": {},
   "source": [
    "\"construct\" is based on the Human Genome Organization (HUGO) Gene Nomenclature Committee (HGNC) naming conventions for genes and leverages regular expressions to let the annotator abide by them. Those expressions comprise various combinations of letters and numbers and certain fixed terms for shorter terms to avoid underfitting. In addition, the CIViC database for variants has also been included for a better recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ed53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure(doc):\n",
    "    for tok in doc:\n",
    "        if bool(re.search(r\"[a-zA-Z]{4}\\d{2}\", tok.text))==True or bool(re.search(r\"[a-zA-Z]{5}\\d{1}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"[a-zA-Z]{4}\\d{1}\", tok.text))==True or bool(re.search(r\"[A-Z]{5}\\d{1}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"[A-Z]{5}\\d{2}\", tok.text))==True or bool(re.search(r\"[A-Z]{3}\\d{2}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"[a-zA-Z]{2}\\d{3}[a-zA-Z]{2}\", tok.text))==True or bool(re.search(r\"[a-zA-Z]{1}\\d{3}[a-zA-Z]{1}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"[A-Z]{3}\\d{2}\", tok.text))==True or bool(re.search(r\"[A-Z]{6}\\d{1}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"[A-Z]{3}\\d{3}\", tok.text))==True or bool(re.search(r\"[p]\\d{2}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"CYP[a-zA-Z0-9]{3}\", tok.text))==True or bool(re.search(r\"CYP[a-zA-Z0-9]{2}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"[A-Z]{3}\\d{1}\", tok.text))==True or bool(re.search(r\"[A-Z]{2}\\d{2}\", tok.text))==True\\\n",
    "        or bool(re.search(r\"^CK.\", tok.text))==True or bool(re.search(r\"^PD-..\", tok.text))==True or bool(re.search(r\"^PS[MA|A]\", tok.text))==True or tok.text.lower in CIVIC_variants_lower:\n",
    "            yield tok.i, tok.i+1, \"Gen\"\n",
    "construct = heuristics.FunctionAnnotator(\"construct\", structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9bc3aae-f3c3-4d76-93f1-ea2b44d8e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Labeling Functions to data\n",
    "\n",
    "lfs = [construct, cue_civic, omim, cue_cosmic_census]\n",
    "\n",
    "\n",
    "#For Quick Run with Random Sentences!\n",
    "#random_files = files_df.sample(n = 10000)\n",
    "docs = []\n",
    "\n",
    "for file_idx, doc in zip(files_df.reset_index().iterrows(), nlp.pipe(files_df.text, batch_size=32,disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\",\\\n",
    "                                                                                             'morphologizer', 'ner'])):\n",
    "    i, row = file_idx\n",
    "    for lf in lfs:\n",
    "        doc = lf(doc)\n",
    "    docs.append(doc)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i}/{len(files_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00ac4b-8333-44bf-9274-ab6734810bbb",
   "metadata": {},
   "source": [
    "# Labeling Function Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7efce228-337e-4bd0-8dfc-79766289efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate agreement, overlap, create heatmap\n",
    "\n",
    "def convert_gold_labels(file_name):\n",
    "    db = DocBin().from_disk(file_name)\n",
    "    gold_docs = list(db.get_docs(nlp.vocab))\n",
    "\n",
    "    for g in gold_docs:\n",
    "        spans = [Span(g, span.start, span.end, 'Gen') for span in g.spans['Gene or Protein']]\n",
    "        ents = []\n",
    "        for s in spans:\n",
    "            overlap = False\n",
    "            for i, e in enumerate(ents): # Check for overlap\n",
    "                if s.start <= e.start and s.end >= e.end:\n",
    "                    ents[i] = s # Replace with larger span\n",
    "                    overlap = True\n",
    "                    break\n",
    "            if not overlap:\n",
    "                ents.append(s)\n",
    "        g.set_ents(ents)\n",
    "        g.spans[\"Gene or Protein\"] = []\n",
    "    return gold_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc719768",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_docs = convert_gold_labels('gold_labels.spacy')\n",
    "gold_docs_test = convert_gold_labels('gold_test.spacy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bcc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.docbin_writer(gold_docs, \"aml4dh-skweak/goldig.spacy\")\n",
    "utils.docbin_writer(gold_docs_test, \"aml4dh-skweak/goldig_test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LFs to gold documents\n",
    "for g in gold_docs:\n",
    "    for lf in lfs:\n",
    "        g = lf(g)\n",
    "    # Why does this still have a \"Variant\" key?\n",
    "    if 'Variant' in g.spans:\n",
    "        del g.spans['Variant']\n",
    "    g = hmm(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM / LFs vs. Gold-Standard\n",
    "#evaluate(gold_docs, ['Gen'], ['lf15', 'hmm'])\n",
    "evaluate(gold_docs, ['Gen'], [l.name for l in lfs[0:14]] + ['hmm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eeb61a-975b-43bf-9a30-4d7d3bc40b65",
   "metadata": {},
   "source": [
    "# Label Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf2dd2ea-50b3-4a17-8905-30545b57a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train HMM, Majority Voter, etc...\n",
    "\n",
    "#voter = skweak.voting.SequentialMajorityVoter(\"maj_voter\", labels=[\"Gen\"])\n",
    "#voter.fit(docs)\n",
    "hmm = generative.HMM(\"hmm\", [\"Gen\"])\n",
    "hmm.fit(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8463328-767e-4c89-a5e0-d62a496fc1bb",
   "metadata": {},
   "source": [
    "# Load Gold-Standard Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344d9203-633c-49cc-8732-0bab2691d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dev / test data\n",
    "# ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c793b3ee-500a-4d28-8086-27a5e456fb27",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4907d92c-3ead-411c-aa30-0d07215fb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NER model with spaCy\n",
    "\n",
    "!spacy train config.cfg --paths.train aml4dh-skweak/goldig.spacy  --paths.dev aml4dh-skweak/goldig_test.spacy --output aml4dh-skweak/goldig --gpu-id 0 --code training.py\n",
    "\n",
    "\n",
    "#!spacy train config.cfg --paths.train aml4dh-skweak/training.spacy  --paths.dev aml4dh-skweak/goldig_test.spacy --output aml4dh-skweak/goldig --gpu-id 0 --code training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a809fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best performing NER model\n",
    "nlp = spacy.load(\"aml4dh-skweak/goldig/model-best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42435ea6-98d4-4dbe-9c45-188ab8d4d690",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c92a75c-31d2-4d99-8d80-bbd88fb62fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate HMM, LFs, NER model on dev / test data -> final performance table\n",
    "\n",
    "for d_gold, d_pred in zip(gold_docs, gold_docs_for_lfa):\n",
    "    d_pred.set_ents([])\n",
    "    d_pred = nlp_pred(d_pred)\n",
    "    d_gold.spans['ner_model'] = d_pred.ents\n",
    "    \n",
    "evaluate(gold_docs, ['Gen'], ['ner_model'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
